{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115f982-33d2-43df-8ead-d407c3699112",
   "metadata": {},
   "source": [
    "# New phrase \n",
    "\n",
    "## Overview\n",
    "This notebook is designed for analyzing a dataset of papers to identify the new phrases.\n",
    "For each new phrase, the ID is the first paper is identified and the number of subsequent papers the re-use the phrase are counted.\n",
    "\n",
    "A baseline of phrases is defined. phrases that appear in the baseline are not considered as new phrases. \n",
    "\n",
    "The script reads processed data from a CSV file, compares each phrase against the baseline, and counts the occurrences of the new phrases. The results are then written to a new CSV file.\n",
    "\n",
    "## Workflow\n",
    "- **Setting Up the Environment**: The script starts by importing necessary libraries and adjusting the system’s maximum integer size to avoid errors when reading large lines from the CSV file.\n",
    "\n",
    "- **Counting the Number of Papers:** It calculates the total number of papers to be processed by counting the lines in the processed data CSV file. This is needed to keep track of the process with a progress bar (tqdm).\n",
    "\n",
    "- **Creating the Baseline:** A baseline set of phrases is created from papers published before a specified baseline year. The notebook reads each paper and adds phrases to the baseline set if the paper’s publication year is before the baseline year.\n",
    "\n",
    "- **Counting New phrases:** The notebook then reads the processed data of each paper and counts the occurrence of phrases that are not in the baseline set. Each new phrase’s count and the ID of the paper in which it first appeared are stored.\n",
    "\n",
    "- **Exporting the Results:** The counted new phrases, along with the ID of the paper in which each phrase first appeared and the total count of each phrase’s occurrence, are written to a new CSV file. phrases that only appeared once are filtered out.\n",
    "\n",
    "## Output\n",
    "The notebook generates a CSV file containing each new phrase that is not part of the baseline, the ID of the paper in which the phrase first appeared, and the total count of the phrase’s occurrence in all papers. Each row in the file represents a unique new phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b58a646-da3b-4edf-ae4f-e355bc07213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "## Increase the max size of a line reading, otherwise an error is raised\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1447055c-b21a-4b07-b0f5-9f2173850cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the number of papers to process...\n",
      "Creating the baseline...\n",
      "Iterating over the baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31417eb40aeb4b3bbcc659c0acb69bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new phrases...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1627469abf15477cbb4fdbaf5d3753b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/746 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9bdc866647427e8c01d2035c5a0216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of papers\n",
    "print('Get the number of papers to process...')\n",
    "with open('../data/processed/papers_phrases.csv', 'r', encoding='utf-8') as file:\n",
    "    line_count = sum(1 for line in file)\n",
    "total_papers = line_count - 1  # Subtract 1 for the header\n",
    "\n",
    "print('Creating the baseline...')\n",
    "# Creating a baseline set of phrases from papers published before the baseline year\n",
    "baseline_year = 2000\n",
    "baseline = set()\n",
    "\n",
    "print('Iterating over the baseline...')\n",
    "with open('../data/raw/papers_raw.csv', 'r', encoding='utf-8') as raw_reader, \\\n",
    "        open('../data/processed/papers_phrases.csv', 'r', encoding='utf-8') as processed_reader:\n",
    "        \n",
    "    csv_raw_reader = csv.reader(raw_reader, delimiter='\\t', quotechar='\"')\n",
    "    csv_processed_reader = csv.reader(processed_reader, delimiter=',', quotechar='\"')\n",
    "\n",
    "    # Skipping the headers\n",
    "    next(csv_raw_reader)\n",
    "    next(csv_processed_reader)\n",
    "    \n",
    "    # Iterating over each paper and adding phrases to the baseline if the paper was published before the baseline year\n",
    "    for line_raw, line_processed in tqdm(zip(csv_raw_reader, csv_processed_reader), total=total_papers):\n",
    "        if int(line_raw[1].split('-')[0]) > baseline_year:\n",
    "            continue\n",
    "            \n",
    "        text = set(line_processed[1].split() + line_processed[2].split())\n",
    "        baseline.update(text)\n",
    "        \n",
    "# Counting the occurrence of new phrases that are not in the baseline\n",
    "counter = collections.Counter()\n",
    "paperIds = collections.defaultdict()\n",
    "\n",
    "print('Calculating new phrases...')\n",
    "# Reading the processed papers data and counting new phrases\n",
    "with open('../data/processed/papers_phrases.csv', 'r', encoding='utf-8') as reader:\n",
    "    csv_reader = csv.reader(reader, delimiter=',', quotechar='\"')\n",
    "    next(csv_reader)  # Skip header\n",
    "\n",
    "    for line in tqdm(csv_reader, total=total_papers):\n",
    "        paperID = int(line[0])\n",
    "        text = set(line[1].split() + line[2].split())\n",
    "        \n",
    "        for token in text:\n",
    "            if token in baseline:\n",
    "                continue\n",
    "                \n",
    "            if token not in counter:\n",
    "                counter[token] = 0\n",
    "                paperIds[token] = paperID\n",
    "            else:\n",
    "                counter[token] += 1\n",
    "                \n",
    "print('Exporting the results...')\n",
    "# Exporting the results to a new CSV file\n",
    "with open('../data/metrics/new_phrase.csv', 'w', encoding=\"utf-8\") as writer:\n",
    "    writer.write('phrase,PaperID,reuse\\n') # Header\n",
    "\n",
    "    for token, paperID, reuse in tqdm(zip(counter.keys(), paperIds.values(), counter.values()), total=len(counter)):\n",
    "        # Filter out if reused only once\n",
    "        if reuse == 0:\n",
    "            continue\n",
    "\n",
    "        writer.write(f'{token},{paperID},{reuse}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
