{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115f982-33d2-43df-8ead-d407c3699112",
   "metadata": {},
   "source": [
    "# New trigram \n",
    "\n",
    "## Overview\n",
    "This notebook is designed for analyzing a dataset of papers to identify the new trigrams.\n",
    "For each new trigram, the ID is the first paper is identified and the number of subsequent papers the re-use the trigram are counted.\n",
    "\n",
    "A baseline of trigrams is defined. Trigrams that appear in the baseline are not considered as new trigrams. \n",
    "\n",
    "The script reads processed data from a CSV file, compares each trigram against the baseline, and counts the occurrences of the new trigrams. The results are then written to a new CSV file.\n",
    "\n",
    "## Workflow\n",
    "- **Setting Up the Environment**: The script starts by importing necessary libraries and adjusting the system’s maximum integer size to avoid errors when reading large lines from the CSV file.\n",
    "\n",
    "- **Counting the Number of Papers:** It calculates the total number of papers to be processed by counting the lines in the processed data CSV file. This is needed to keep track of the process with a progress bar (tqdm).\n",
    "\n",
    "- **Creating the Baseline:** A baseline set of trigrams is created from papers published before a specified baseline year. The notebook reads each paper and adds trigrams to the baseline set if the paper’s publication year is before the baseline year.\n",
    "\n",
    "- **Counting New Trigrams:** The notebook then reads the processed data of each paper and counts the occurrence of trigrams that are not in the baseline set. Each new trigram’s count and the ID of the paper in which it first appeared are stored.\n",
    "\n",
    "- **Exporting the Results:** The counted new trigrams, along with the ID of the paper in which each trigram first appeared and the total count of each trigram’s occurrence, are written to a new CSV file. Trigrams that only appeared once are filtered out.\n",
    "\n",
    "## Output\n",
    "The notebook generates a CSV file containing each new trigram that is not part of the baseline, the ID of the paper in which the trigram first appeared, and the total count of the trigram’s occurrence in all papers. Each row in the file represents a unique new trigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58a646-da3b-4edf-ae4f-e355bc07213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "## Increase the max size of a line reading, otherwise an error is raised\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1447055c-b21a-4b07-b0f5-9f2173850cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of papers\n",
    "print('Get the number of papers to process...')\n",
    "with open('../data/processed/papers_trigrams.csv', 'r', encoding='utf-8') as file:\n",
    "    line_count = sum(1 for line in file)\n",
    "total_papers = line_count - 1  # Subtract 1 for the header\n",
    "\n",
    "print('Creating the baseline...')\n",
    "# Creating a baseline set of trigrams from papers published before the baseline year\n",
    "baseline_year = 2000\n",
    "baseline = set()\n",
    "\n",
    "print('Iterating over the baseline...')\n",
    "with open('../data/raw/papers_raw.csv', 'r', encoding='utf-8') as raw_reader, \\\n",
    "        open('../data/processed/papers_trigrams.csv', 'r', encoding='utf-8') as processed_reader:\n",
    "        \n",
    "    csv_raw_reader = csv.reader(raw_reader, delimiter='\\t', quotechar='\"')\n",
    "    csv_processed_reader = csv.reader(processed_reader, delimiter=',', quotechar='\"')\n",
    "\n",
    "    # Skipping the headers\n",
    "    next(csv_raw_reader)\n",
    "    next(csv_processed_reader)\n",
    "    \n",
    "    # Iterating over each paper and adding trigrams to the baseline if the paper was published before the baseline year\n",
    "    for line_raw, line_processed in tqdm(zip(csv_raw_reader, csv_processed_reader), total=total_papers):\n",
    "        if int(line_raw[1].split('-')[0]) > baseline_year:\n",
    "            continue\n",
    "            \n",
    "        text = set(line_processed[1].split() + line_processed[2].split())\n",
    "        baseline.update(text)\n",
    "        \n",
    "# Counting the occurrence of new trigrams that are not in the baseline\n",
    "counter = collections.Counter()\n",
    "paperIds = collections.defaultdict()\n",
    "\n",
    "print('Calculating new trigrams...')\n",
    "# Reading the processed papers data and counting new trigrams\n",
    "with open('../data/processed/papers_trigrams.csv', 'r', encoding='utf-8') as reader:\n",
    "    csv_reader = csv.reader(reader, delimiter=',', quotechar='\"')\n",
    "    next(csv_reader)  # Skip header\n",
    "\n",
    "    for line in tqdm(csv_reader, total=total_papers):\n",
    "        paperID = int(line[0])\n",
    "        text = set(line[1].split() + line[2].split())\n",
    "        \n",
    "        for token in text:\n",
    "            if token in baseline:\n",
    "                continue\n",
    "                \n",
    "            if token not in counter:\n",
    "                counter[token] = 0\n",
    "                paperIds[token] = paperID\n",
    "            else:\n",
    "                counter[token] += 1\n",
    "                \n",
    "print('Exporting the results...')\n",
    "# Exporting the results to a new CSV file\n",
    "with open('../data/metrics/new_trigram.csv', 'w', encoding=\"utf-8\") as writer:\n",
    "    writer.write('trigram,PaperID,reuse\\n') # Header\n",
    "\n",
    "    for token, paperID, reuse in tqdm(zip(counter.keys(), paperIds.values(), counter.values()), total=len(counter)):\n",
    "        # Filter out if reused only once\n",
    "        if reuse == 0:\n",
    "            continue\n",
    "\n",
    "        writer.write(f'{token},{paperID},{reuse}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
